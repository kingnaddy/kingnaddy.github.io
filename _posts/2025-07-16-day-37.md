---
layout: post
title: "Day 37 – XGBoost, RandomSearchCV & Firebase Feature Mismatch"
date: 2025-07-16
author: Noble Adike
permalink: /day37.html
tags: ["Machine Learning", "Route Optimization", "XGBoost", "Random Forest", "RandomSearchCV", "Precision", "Firebase", "Feature Engineering", "Model Deployment"]

what_i_learned: |
  Today I continued refining our ML model for route optimization. We faced major class imbalance challenges when predicting fill urgency within short timeframes (1–12 hrs). To tackle this, we experimented with both XGBoost and Random Forest classifiers. After tuning with RandomizedSearchCV, we reached ~90% accuracy but only ~55% precision due to the imbalance. 

  Despite these limitations, we decided to proceed with the model due to time constraints. I then moved on to model deployment using joblib. However, we ran into issues when applying the trained model to raw data from Firebase—caused by mismatches in expected vs. actual feature columns. This was mostly due to missing one-hot encoded variables like 'season_Spring', 'fill_category_Low' etc.

blockers: |
  Low model precision for minority fill classes (1–12 hr range).Feature mismatch errors during deployment due to inconsistent encoding between training and Firebase data.

reflection: |
  This was a tough but valuable debugging day. While our model shows high accuracy, we learned that precision is just as critical for real-world deployment, especially in imbalanced scenarios. The deployment errors reminded me how vital consistent preprocessing is—especially when working with one-hot encoding and raw real-time data. Tomorrow, I’ll work on aligning data pipelines to fix this.
---
